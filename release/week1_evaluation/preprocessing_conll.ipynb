{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a0e10ca872e897c6910ad37f3c949e0e",
     "grade": false,
     "grade_id": "cell-0ade5e9eed59fa5e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Preprocessing Files\n",
    "Different sources and tools may make use of different formats to represent information and output may not directly correspond.\n",
    "In this course, we will mainly or even exclusively work with the conll format (depending on the preprocessing tools you select later on). Nevertheless, there may be differences in tokenization, in class labels or in the number of columns provided. Depending on what the difference is exactly, you may want to adapt the input files or build in handling mechanisms in the steps that follow (evaluation or feature extraction).\n",
    "In this case, we are preparing files for evaluation. You can either handle differences as a step in evaluation or make sure data, class labels and structure align during preprocessing. \n",
    "We recommend you make sure tokens and class labels align during preprocessing. For structure (fix the column that provides the necessary information, fix the delimiter between columns), you may decide yourself. Note though, that the tests in the previous assignments assume that all files make use of the standard conll delimiter (\\t). In this particular case, it is therefore also easier to make sure all files use the same delimiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f5218f494ef603bfee610bc55ec6f39e",
     "grade": false,
     "grade_id": "cell-7e753867a9b9b37f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def matching_tokens(conll1, conll2):\n",
    "    '''\n",
    "    Check whether the tokens of two conll files are aligned\n",
    "    \n",
    "    :param conll1: tokens (or full annotations) from the first conll file\n",
    "    :param conll2: tokens (or full annotations) from the first conll file\n",
    "    \n",
    "    :returns boolean indicating whether tokens match or not\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c777d31ac65e6419f043c464c367278",
     "grade": false,
     "grade_id": "cell-2ab947e371492496",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You will find some suggested functions that support the process of comparing and adapting conll files below.\n",
    "You may want to adapt the arguments and structure (this is not necessary, but feel free if it makes things easier for you). As long as you can run the tests below, this is fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b0e46e2108e232c392bc9d60c022c699",
     "grade": false,
     "grade_id": "cell-6c93b5be48739e09",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def read_in_conll_file(conll_file, delimiter='\\t'):\n",
    "    '''\n",
    "    Read in conll file and return structured object\n",
    "    \n",
    "    :param conll_file: path to conll_file\n",
    "    :param delimiter: specifies how columns are separated. Tabs are standard in conll\n",
    "    \n",
    "    :returns structured representation of information included in conll file\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e38ac1a212bc47dc45f5e14473ec541a",
     "grade": false,
     "grade_id": "cell-af3c5a411b7d2103",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def convert_annotations(conll_object, annotation_identifier, conversions):\n",
    "    '''\n",
    "    Check which annotations need to be converted for the output to match and convert them\n",
    "    \n",
    "    :param conll_object: structured object with conll annotations\n",
    "    :param annotation_identifier: indicator of how to find the annotations in the object (e.g. key of dictionary, index of list)\n",
    "    :param conversions: pointer to the conversions that apply. This can be external (e.g. a local file with conversions) or internal (e.g. prestructured dictionary). In case of an internal object, you probably want to add a function that creates this from a local file.\n",
    "    \n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "21c763cbaee17cc1ea56d99697595ea0",
     "grade": false,
     "grade_id": "cell-60f9c7a1546da94d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_predefined_conversions(conversion_file):\n",
    "    '''\n",
    "    Read in file with predefined conversions and return structured object that maps old annotation to new annotation\n",
    "    \n",
    "    :param conversion_file: path to conversion file\n",
    "    \n",
    "    :returns object that maps old annotations to new ones\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca3c5d967b958a000123c356dc2a183f",
     "grade": false,
     "grade_id": "cell-37479ed77886f209",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def alignment_okay(conll1, conll2):\n",
    "    '''\n",
    "    Read in two conll files and see if their tokens align\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e1ba8dc16a8d71966acad4f94616a10",
     "grade": false,
     "grade_id": "cell-5412818440d76f8e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef14961da9e6125f73085d576b2791c4",
     "grade": false,
     "grade_id": "cell-9507dcfcd4c75af6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_files(conll1, conll2, column_identifiers, conversions):\n",
    "    '''\n",
    "    Guides the full process of preprocessing files and outputs the modified files.\n",
    "    \n",
    "    :param conll1: path to the first conll input file\n",
    "    :param conll2: path to the second conll input file\n",
    "    :param column_identifiers: object providing the identifiers for target column\n",
    "    :param conversions: path to a file that defines conversions\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4379ce96707758f9815fde6a38e10556",
     "grade": true,
     "grade_id": "cell-a855818840be7e62",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal\n",
    "\n",
    "assert_equal(alignment_okay('data/minigold.csv','data/miniout1.csv'),True)\n",
    "assert_equal(alignment_okay('data/minigold.csv','data/miniout2.csv'),False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
