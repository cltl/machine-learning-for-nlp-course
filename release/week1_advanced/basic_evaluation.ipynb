{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7211cd7f4b9b7d96ec4409ae6655dddc",
     "grade": false,
     "grade_id": "cell-b3dce866d70241bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Basic Evaluation\n",
    "Create a set-up that can determine precision recall and f-score of the system output of multiple systems compared to a gold standard.\n",
    "This component should work with the output of your preprocessing component.\n",
    "It should be possible to call the evaluation script by specifing a gold file and system output files as input, together with any information necessary to correctly process the files.\n",
    "The file will also provide tables in latex form as output. You can choose whether you want to write this to a default outputfile or whether you want to ask for an (obligatory) argument specifying the outputfile.\n",
    "\n",
    "For verification reasons, the program should also output a file called 'evaluation_outcome.txt' that provides the outcome of the evaluation on individual lines. e.g.:\n",
    "system1 I-ORG precision 0.623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7f9054e7d13f21f327b9d0cf84dcfe0",
     "grade": false,
     "grade_id": "cell-b6cce6ab0e0b2c3e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "101b448b5ea5311d769927d37e9e3d9d",
     "grade": true,
     "grade_id": "cell-744abb4dde824eb9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "assert_equal(check_info_in_file(filename, text),True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
